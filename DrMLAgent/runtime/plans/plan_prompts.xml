<?xml version="1.0" encoding="UTF-8"?>
<prompts>
    
    <prompt strategy="task" id="INTRODUCE_SESSION">
        <text>Hi! We will start soon.|As we discussed in class, make sure you have LightSIDE open and the User's Manual ready. Also, have your horizontal.csv and vertical.csv files ready. Refer to the Assignment 3 instruction sheet for clarification.</text>
    </prompt>
    
    <prompt strategy="task" id="GREET">
        <text>Hi, [NAME].</text>
        <text>Nice to meet you, [NAME].</text>
        <text>Howdy, [NAME]!</text>
        <text>Hello, [NAME]!</text>
    </prompt>
    
	<!-- This prompt is said automatically for step-type="greet" if there are multiple users -->    
    <prompt strategy="task" id="INTRODUCE">
        <text>I'm [AGENT NAME]. Take a moment to introduce yourselves.</text>
    </prompt>
    
	<!-- This prompt is said automatically for step-type="greet" if there is only one user -->    
    <prompt strategy="task" id="INTRODUCE_1">
        <text>I'm [AGENT NAME]. Take a moment to introduce yourself.</text>
    </prompt>
    
    <prompt strategy="task" id="INTRODUCE_ASSIGNMENT">
        <text>OK, we are going to do Assignment 3 today. I am here just to structure the activity. You should get substantive help from each other. You can refer to the course materials as resources.</text>
    </prompt>
    
    <prompt strategy="task" id="INTRODUCE_ASSIGNMENT_1">
        <text>OK, we are going to do Assignment 3 today. I am here just to structure the activity. If you need substantive help, you can ask the instructor. But try to refer to course materials as resources first.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_1">
        <text>The first thing we are going to do is explore your horizontal.csv and vertical.csv files. There are 4 spreadsheet tabs to the left. Find an empty one labeled Horizontal Sheet. Then open your horizontal.csv file in a spreadsheet program like Excel and copy its cells into the Horizontal Sheet tab. Similarly, copy the cells from your vertical.csv file into an open Vertical Sheet tab.|Press the "Ready" button or type "ready" when you are ready.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_1_1">
        <text>The first thing we are going to do is explore your horizontal.csv and vertical.csv files. There should be 4 spreadsheet tabs in the upper left but you will use only 2 of them. Open one labeled Horizontal Sheet. Then open your horizontal.csv file in a spreadsheet program like Excel and copy its cells into the Horizontal Sheet tab. Similarly, copy the cells from your vertical.csv file into one of the Vertical Sheet tabs.|Press the "Ready" button or type "Ready" when you are ready.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_2">
        <text>Decide together on 4 problematic features. 2 of these features should be based on a horizontal comparison and the other 2 should be based on a vertical comparison.  You will each have a slightly different pair of tables. You can decide on the 4 together by looking through both sets of tables.|Submit "Ready" when you have decided.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_2_1">
        <text>Decide on 4 problematic features. 2 of these features should be based on a horizontal comparison and 2 should be based on a vertical comparison.|Submit "Ready" when you have decided.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_3">
        <text>OK, now that you have picked 4 problematic features to focus on, enter these into the Notes tab. For now, just list each feature name and a justification for thinking it is problematic.|Submit "Ready" when you are ready.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_4">
        <text>Now for the first feature, use the Documents Display feature in LightSIDE to find examples where the feature appears in the upper right error cell of the confusion matrix. Share the examples in the chat, and for each example, say what you observe about it. You should each try to contribute at least 2 different examples.|Submit "Ready" when you are ready.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_4_1">
        <text>Now for the first feature, use the Documents Display feature in LightSIDE to find examples where the feature appears in the upper right error cell of the confusion matrix. Share the examples in the chat, and for each example, say what you observe about it. You should try to contribute at least 4 different examples.|Submit "Ready" when you are ready.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_5">
        <text>Now write a summary in the Notes about the examples you found for feature 1 that illustrate the misclassifications that are happening.|Submit "Ready" when you are ready.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_6">
        <text>Now, again for the first feature, use the Documents Display feature in LightSIDE to find examples where the feature appears in the lower right cell of the confusion matrix. These are examples that were correctly classified. Share the examples in the chat, and for each example you contribute, say what you observe about it. You should each try to contribute at least 2 different examples. What do you think distinguishes the examples that were correctly classified from the ones that were not? This should give you some idea about what new features might be added to the feature space.|Submit "Ready" when you are ready.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_6_1">
        <text>Now, again for the first feature, use the Documents Display feature in LightSIDE to find examples where the feature appears in the lower right cell of the confusion matrix. These are examples that were correctly classified. Share the examples in the chat, and for each example you contribute, say what you observe about it. You should try to contribute at least 4 different examples. What do you think distinguishes the examples that were correctly classified from the ones that were not? This should give you some idea about what new features might be added to the feature space.|Submit "Ready" when you are ready.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_7">
        <text>Now write a summary in the Notes about the examples you found for feature 1 that illustrate the correct classifications that are happening.|Submit "Ready" when you are ready.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_8">
        <text>Now discuss what you think the model is missing that leads to it making an incorrect prediction sometimes and a correct prediction sometimes. Enter your reasoning in the Notes.|Submit "Ready" when you are ready.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_9">
        <text>Now discuss what you think a potential solution would be -- what would you propose to add to the feature space on the extract features panel? Discuss your ideas, and then write what you decide in the Notes.|Submit "Ready" when you are ready.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_9_1">
        <text>Now think about what a potential solution would be -- what would you propose to add to the feature space on the extract features panel? Write what you decide in the Notes.|Submit "Ready" when you are ready.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_10">
        <text>Now, until no later than 9:10, work on the other 3 features the same as you did above. By 9:10, you should be ready to try out your ideas for adding new features.|Submit "Ready" when you are ready to continue to the last step.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_11">
        <text>It's time to run the final experiment. You should each run the experiment on your own computer.|Go to the extract features panel and make your proposed adjustments to the feature extraction setup. Extract the new feature space. Then go to the Build Models panel and run the cross-validation. Note that it is probably still set up with the supplied test set option -- set it back to cross-validation. Run the cross-validation and enter the result in the Notes. If you can find the result you had from the baseline experiment you ran before, enter that as well. Finally, go to the Compare models panel to see whether your adjustment had a significant impact on the results, and enter your finding in the Notes.</text>
    </prompt>
    
    <prompt strategy="task" id="PROMPT_STEP_11_1">
        <text>It's time to run the final experiment.|Go to the extract features panel and make your proposed adjustments to the feature extraction setup. Extract the new feature space. Then go to the Build Models panel and run the cross-validation. Note that it is probably still set up with the supplied test set option -- set it back to cross-validation. Run the cross-validation and enter the result in the Notes. If you can find the result you had from the baseline experiment you ran before, enter that as well. Finally, go to the Compare models panel to see whether your adjustment had a significant impact on the results, and enter your finding in the Notes.</text>
    </prompt>
 
 
 <!-- ================================ -->
 <!-- The following prompts are unused -->
 <!-- ================================ -->
    
    <prompt strategy="task" id="SETUP">
        <text>While I won't tell you answers directly, I can help guide the group' discussion.</text>
    </prompt>
    
    <prompt strategy="task" id="INSTRUCTIONS">
    	<text>Once you get an idea of what's going on, replace these prompts with something domain appropriate!</text>
    </prompt>
   
    <prompt strategy="task" id="WHITEBOARD_INSTRUCTIONS">
    	<text>I will share images to the whiteboard to help/guide you</text>
    </prompt> 
    
    <prompt strategy="task" id="END_MACRO">
    	<text>...</text>
    </prompt>
    
    <prompt strategy="task" id="ABOUT_TUTORIALS">
    	<text>Now I'll start an interactive dialogue.</text>
    </prompt>
    
    <prompt strategy="task" id="INTRO_SHORT">
    	<text>Welcome! I'm [AGENT NAME]. I'm here to have an interactive dialogue with you to assist you in your programming task.</text>
    </prompt>
   
    <prompt strategy="task" id="ABOUT_LISTENING">
    	<text>Note that other agent behaviors (like accountable-talk style listening) will be suppressed while the dialogue is underway.</text>
    </prompt>
    
<!--     
    <prompt strategy="task" id="END_GREETINGS">
        <text>When you've finished introducing yourself, type "I'm Ready" or press the "I'm Ready" button to begin.</text>
    </prompt>
 -->    
 
</prompts>